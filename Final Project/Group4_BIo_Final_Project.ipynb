{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioinformatics Final Project: Group 4\n",
    "### Coral Host taken into consideration is OANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Gene Expression data and the meta data files for the Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A0A011QK89</th>\n",
       "      <th>A0A023I7E1</th>\n",
       "      <th>A0A067XMP1</th>\n",
       "      <th>A0A067YMX8</th>\n",
       "      <th>A0A075HNX4</th>\n",
       "      <th>A0A0A0RM07</th>\n",
       "      <th>A0A0B4KGY6</th>\n",
       "      <th>A0A0B6VQ48</th>\n",
       "      <th>A0A0B7P9G0</th>\n",
       "      <th>A0A0G2JDV3</th>\n",
       "      <th>...</th>\n",
       "      <th>S0EMV0</th>\n",
       "      <th>S8GJB7</th>\n",
       "      <th>V6CLA2</th>\n",
       "      <th>W0LYS5</th>\n",
       "      <th>W0TIW1</th>\n",
       "      <th>W7JLR6</th>\n",
       "      <th>W7JX98</th>\n",
       "      <th>W7K9M0</th>\n",
       "      <th>W7NDQ0</th>\n",
       "      <th>X1WER2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M_c1_C</th>\n",
       "      <td>3.907570</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>3.004398</td>\n",
       "      <td>2.703474</td>\n",
       "      <td>2.986870</td>\n",
       "      <td>2.241169</td>\n",
       "      <td>2.521235</td>\n",
       "      <td>3.692186</td>\n",
       "      <td>3.004398</td>\n",
       "      <td>6.353335</td>\n",
       "      <td>...</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>1.856850</td>\n",
       "      <td>3.104000</td>\n",
       "      <td>3.119761</td>\n",
       "      <td>3.371791</td>\n",
       "      <td>1.856850</td>\n",
       "      <td>2.359892</td>\n",
       "      <td>4.727864</td>\n",
       "      <td>4.686284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_c3_C</th>\n",
       "      <td>5.441870</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>2.535626</td>\n",
       "      <td>3.657173</td>\n",
       "      <td>3.478619</td>\n",
       "      <td>2.503367</td>\n",
       "      <td>3.106804</td>\n",
       "      <td>4.619353</td>\n",
       "      <td>4.672777</td>\n",
       "      <td>7.503357</td>\n",
       "      <td>...</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>1.869137</td>\n",
       "      <td>2.976699</td>\n",
       "      <td>3.426356</td>\n",
       "      <td>3.944844</td>\n",
       "      <td>4.232551</td>\n",
       "      <td>2.173351</td>\n",
       "      <td>2.273015</td>\n",
       "      <td>6.026444</td>\n",
       "      <td>6.010146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_c5_C</th>\n",
       "      <td>5.331988</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>3.125354</td>\n",
       "      <td>3.570151</td>\n",
       "      <td>3.630813</td>\n",
       "      <td>2.891829</td>\n",
       "      <td>2.891829</td>\n",
       "      <td>4.273808</td>\n",
       "      <td>5.297177</td>\n",
       "      <td>7.510740</td>\n",
       "      <td>...</td>\n",
       "      <td>1.948261</td>\n",
       "      <td>2.346861</td>\n",
       "      <td>3.570151</td>\n",
       "      <td>2.414528</td>\n",
       "      <td>3.368204</td>\n",
       "      <td>4.119319</td>\n",
       "      <td>2.729975</td>\n",
       "      <td>2.684824</td>\n",
       "      <td>5.862211</td>\n",
       "      <td>5.935485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_c6_C</th>\n",
       "      <td>5.619051</td>\n",
       "      <td>1.974893</td>\n",
       "      <td>2.605541</td>\n",
       "      <td>3.519751</td>\n",
       "      <td>2.948207</td>\n",
       "      <td>2.404832</td>\n",
       "      <td>3.137391</td>\n",
       "      <td>4.295079</td>\n",
       "      <td>4.585000</td>\n",
       "      <td>7.673688</td>\n",
       "      <td>...</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>2.544092</td>\n",
       "      <td>2.905994</td>\n",
       "      <td>2.544092</td>\n",
       "      <td>3.662709</td>\n",
       "      <td>4.478651</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>2.477620</td>\n",
       "      <td>6.219767</td>\n",
       "      <td>5.997715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_c7_C</th>\n",
       "      <td>5.021363</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>2.913924</td>\n",
       "      <td>3.443582</td>\n",
       "      <td>3.627241</td>\n",
       "      <td>2.838415</td>\n",
       "      <td>2.937903</td>\n",
       "      <td>4.301555</td>\n",
       "      <td>4.861119</td>\n",
       "      <td>7.184987</td>\n",
       "      <td>...</td>\n",
       "      <td>1.887821</td>\n",
       "      <td>2.152548</td>\n",
       "      <td>3.050253</td>\n",
       "      <td>2.454656</td>\n",
       "      <td>3.666083</td>\n",
       "      <td>3.930574</td>\n",
       "      <td>2.567736</td>\n",
       "      <td>2.214481</td>\n",
       "      <td>5.709837</td>\n",
       "      <td>5.492568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3484 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        A0A011QK89  A0A023I7E1  A0A067XMP1  A0A067YMX8  A0A075HNX4  \\\n",
       "M_c1_C    3.907570    1.620841    3.004398    2.703474    2.986870   \n",
       "M_c3_C    5.441870    1.620841    2.535626    3.657173    3.478619   \n",
       "M_c5_C    5.331988    1.620841    3.125354    3.570151    3.630813   \n",
       "M_c6_C    5.619051    1.974893    2.605541    3.519751    2.948207   \n",
       "M_c7_C    5.021363    1.620841    2.913924    3.443582    3.627241   \n",
       "\n",
       "        A0A0A0RM07  A0A0B4KGY6  A0A0B6VQ48  A0A0B7P9G0  A0A0G2JDV3  ...  \\\n",
       "M_c1_C    2.241169    2.521235    3.692186    3.004398    6.353335  ...   \n",
       "M_c3_C    2.503367    3.106804    4.619353    4.672777    7.503357  ...   \n",
       "M_c5_C    2.891829    2.891829    4.273808    5.297177    7.510740  ...   \n",
       "M_c6_C    2.404832    3.137391    4.295079    4.585000    7.673688  ...   \n",
       "M_c7_C    2.838415    2.937903    4.301555    4.861119    7.184987  ...   \n",
       "\n",
       "          S0EMV0    S8GJB7    V6CLA2    W0LYS5    W0TIW1    W7JLR6    W7JX98  \\\n",
       "M_c1_C  1.620841  1.620841  1.856850  3.104000  3.119761  3.371791  1.856850   \n",
       "M_c3_C  1.620841  1.869137  2.976699  3.426356  3.944844  4.232551  2.173351   \n",
       "M_c5_C  1.948261  2.346861  3.570151  2.414528  3.368204  4.119319  2.729975   \n",
       "M_c6_C  1.620841  2.544092  2.905994  2.544092  3.662709  4.478651  1.620841   \n",
       "M_c7_C  1.887821  2.152548  3.050253  2.454656  3.666083  3.930574  2.567736   \n",
       "\n",
       "          W7K9M0    W7NDQ0    X1WER2  \n",
       "M_c1_C  2.359892  4.727864  4.686284  \n",
       "M_c3_C  2.273015  6.026444  6.010146  \n",
       "M_c5_C  2.684824  5.862211  5.935485  \n",
       "M_c6_C  2.477620  6.219767  5.997715  \n",
       "M_c7_C  2.214481  5.709837  5.492568  \n",
       "\n",
       "[5 rows x 3484 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Gene Expression Data\n",
    "Gene_expression = pd.read_csv('normalized_counts_vst.csv', index_col = 0).T\n",
    "Gene_expression.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Clade</th>\n",
       "      <th>Host</th>\n",
       "      <th>Dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M_c1_C</td>\n",
       "      <td>C</td>\n",
       "      <td>MCAV</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M_c3_C</td>\n",
       "      <td>C</td>\n",
       "      <td>MCAV</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M_c5_C</td>\n",
       "      <td>C</td>\n",
       "      <td>MCAV</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M_c6_C</td>\n",
       "      <td>C</td>\n",
       "      <td>MCAV</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M_c7_C</td>\n",
       "      <td>C</td>\n",
       "      <td>MCAV</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sample_ID Clade  Host Dominant\n",
       "0    M_c1_C     C  MCAV      Yes\n",
       "1    M_c3_C     C  MCAV      Yes\n",
       "2    M_c5_C     C  MCAV      Yes\n",
       "3    M_c6_C     C  MCAV       No\n",
       "4    M_c7_C     C  MCAV      Yes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the metadata file.\n",
    "metadata = pd.read_csv(\"metadata.csv\")\n",
    "metadata.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A0A011QK89</th>\n",
       "      <th>A0A023I7E1</th>\n",
       "      <th>A0A067XMP1</th>\n",
       "      <th>A0A067YMX8</th>\n",
       "      <th>A0A075HNX4</th>\n",
       "      <th>A0A0A0RM07</th>\n",
       "      <th>A0A0B4KGY6</th>\n",
       "      <th>A0A0B6VQ48</th>\n",
       "      <th>A0A0B7P9G0</th>\n",
       "      <th>A0A0G2JDV3</th>\n",
       "      <th>...</th>\n",
       "      <th>W0TIW1</th>\n",
       "      <th>W7JLR6</th>\n",
       "      <th>W7JX98</th>\n",
       "      <th>W7K9M0</th>\n",
       "      <th>W7NDQ0</th>\n",
       "      <th>X1WER2</th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Clade</th>\n",
       "      <th>Host</th>\n",
       "      <th>Dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.907570</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>3.004398</td>\n",
       "      <td>2.703474</td>\n",
       "      <td>2.986870</td>\n",
       "      <td>2.241169</td>\n",
       "      <td>2.521235</td>\n",
       "      <td>3.692186</td>\n",
       "      <td>3.004398</td>\n",
       "      <td>6.353335</td>\n",
       "      <td>...</td>\n",
       "      <td>3.119761</td>\n",
       "      <td>3.371791</td>\n",
       "      <td>1.856850</td>\n",
       "      <td>2.359892</td>\n",
       "      <td>4.727864</td>\n",
       "      <td>4.686284</td>\n",
       "      <td>M_c1_C</td>\n",
       "      <td>C</td>\n",
       "      <td>MCAV</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.441870</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>2.535626</td>\n",
       "      <td>3.657173</td>\n",
       "      <td>3.478619</td>\n",
       "      <td>2.503367</td>\n",
       "      <td>3.106804</td>\n",
       "      <td>4.619353</td>\n",
       "      <td>4.672777</td>\n",
       "      <td>7.503357</td>\n",
       "      <td>...</td>\n",
       "      <td>3.944844</td>\n",
       "      <td>4.232551</td>\n",
       "      <td>2.173351</td>\n",
       "      <td>2.273015</td>\n",
       "      <td>6.026444</td>\n",
       "      <td>6.010146</td>\n",
       "      <td>M_c3_C</td>\n",
       "      <td>C</td>\n",
       "      <td>MCAV</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.331988</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>3.125354</td>\n",
       "      <td>3.570151</td>\n",
       "      <td>3.630813</td>\n",
       "      <td>2.891829</td>\n",
       "      <td>2.891829</td>\n",
       "      <td>4.273808</td>\n",
       "      <td>5.297177</td>\n",
       "      <td>7.510740</td>\n",
       "      <td>...</td>\n",
       "      <td>3.368204</td>\n",
       "      <td>4.119319</td>\n",
       "      <td>2.729975</td>\n",
       "      <td>2.684824</td>\n",
       "      <td>5.862211</td>\n",
       "      <td>5.935485</td>\n",
       "      <td>M_c5_C</td>\n",
       "      <td>C</td>\n",
       "      <td>MCAV</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.619051</td>\n",
       "      <td>1.974893</td>\n",
       "      <td>2.605541</td>\n",
       "      <td>3.519751</td>\n",
       "      <td>2.948207</td>\n",
       "      <td>2.404832</td>\n",
       "      <td>3.137391</td>\n",
       "      <td>4.295079</td>\n",
       "      <td>4.585000</td>\n",
       "      <td>7.673688</td>\n",
       "      <td>...</td>\n",
       "      <td>3.662709</td>\n",
       "      <td>4.478651</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>2.477620</td>\n",
       "      <td>6.219767</td>\n",
       "      <td>5.997715</td>\n",
       "      <td>M_c6_C</td>\n",
       "      <td>C</td>\n",
       "      <td>MCAV</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.021363</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>2.913924</td>\n",
       "      <td>3.443582</td>\n",
       "      <td>3.627241</td>\n",
       "      <td>2.838415</td>\n",
       "      <td>2.937903</td>\n",
       "      <td>4.301555</td>\n",
       "      <td>4.861119</td>\n",
       "      <td>7.184987</td>\n",
       "      <td>...</td>\n",
       "      <td>3.666083</td>\n",
       "      <td>3.930574</td>\n",
       "      <td>2.567736</td>\n",
       "      <td>2.214481</td>\n",
       "      <td>5.709837</td>\n",
       "      <td>5.492568</td>\n",
       "      <td>M_c7_C</td>\n",
       "      <td>C</td>\n",
       "      <td>MCAV</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3488 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A0A011QK89  A0A023I7E1  A0A067XMP1  A0A067YMX8  A0A075HNX4  A0A0A0RM07  \\\n",
       "0    3.907570    1.620841    3.004398    2.703474    2.986870    2.241169   \n",
       "1    5.441870    1.620841    2.535626    3.657173    3.478619    2.503367   \n",
       "2    5.331988    1.620841    3.125354    3.570151    3.630813    2.891829   \n",
       "3    5.619051    1.974893    2.605541    3.519751    2.948207    2.404832   \n",
       "4    5.021363    1.620841    2.913924    3.443582    3.627241    2.838415   \n",
       "\n",
       "   A0A0B4KGY6  A0A0B6VQ48  A0A0B7P9G0  A0A0G2JDV3  ...    W0TIW1    W7JLR6  \\\n",
       "0    2.521235    3.692186    3.004398    6.353335  ...  3.119761  3.371791   \n",
       "1    3.106804    4.619353    4.672777    7.503357  ...  3.944844  4.232551   \n",
       "2    2.891829    4.273808    5.297177    7.510740  ...  3.368204  4.119319   \n",
       "3    3.137391    4.295079    4.585000    7.673688  ...  3.662709  4.478651   \n",
       "4    2.937903    4.301555    4.861119    7.184987  ...  3.666083  3.930574   \n",
       "\n",
       "     W7JX98    W7K9M0    W7NDQ0    X1WER2  Sample_ID  Clade  Host  Dominant  \n",
       "0  1.856850  2.359892  4.727864  4.686284     M_c1_C      C  MCAV       Yes  \n",
       "1  2.173351  2.273015  6.026444  6.010146     M_c3_C      C  MCAV       Yes  \n",
       "2  2.729975  2.684824  5.862211  5.935485     M_c5_C      C  MCAV       Yes  \n",
       "3  1.620841  2.477620  6.219767  5.997715     M_c6_C      C  MCAV        No  \n",
       "4  2.567736  2.214481  5.709837  5.492568     M_c7_C      C  MCAV       Yes  \n",
       "\n",
       "[5 rows x 3488 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging the Gene Expression and Meta data together.\n",
    "data = pd.merge(Gene_expression, metadata, left_index = True, right_on = 'Sample_ID')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A0A011QK89</th>\n",
       "      <th>A0A023I7E1</th>\n",
       "      <th>A0A067XMP1</th>\n",
       "      <th>A0A067YMX8</th>\n",
       "      <th>A0A075HNX4</th>\n",
       "      <th>A0A0A0RM07</th>\n",
       "      <th>A0A0B4KGY6</th>\n",
       "      <th>A0A0B6VQ48</th>\n",
       "      <th>A0A0B7P9G0</th>\n",
       "      <th>A0A0G2JDV3</th>\n",
       "      <th>...</th>\n",
       "      <th>S8GJB7</th>\n",
       "      <th>V6CLA2</th>\n",
       "      <th>W0LYS5</th>\n",
       "      <th>W0TIW1</th>\n",
       "      <th>W7JLR6</th>\n",
       "      <th>W7JX98</th>\n",
       "      <th>W7K9M0</th>\n",
       "      <th>W7NDQ0</th>\n",
       "      <th>X1WER2</th>\n",
       "      <th>Host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.907570</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>3.004398</td>\n",
       "      <td>2.703474</td>\n",
       "      <td>2.986870</td>\n",
       "      <td>2.241169</td>\n",
       "      <td>2.521235</td>\n",
       "      <td>3.692186</td>\n",
       "      <td>3.004398</td>\n",
       "      <td>6.353335</td>\n",
       "      <td>...</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>1.856850</td>\n",
       "      <td>3.104000</td>\n",
       "      <td>3.119761</td>\n",
       "      <td>3.371791</td>\n",
       "      <td>1.856850</td>\n",
       "      <td>2.359892</td>\n",
       "      <td>4.727864</td>\n",
       "      <td>4.686284</td>\n",
       "      <td>MCAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.441870</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>2.535626</td>\n",
       "      <td>3.657173</td>\n",
       "      <td>3.478619</td>\n",
       "      <td>2.503367</td>\n",
       "      <td>3.106804</td>\n",
       "      <td>4.619353</td>\n",
       "      <td>4.672777</td>\n",
       "      <td>7.503357</td>\n",
       "      <td>...</td>\n",
       "      <td>1.869137</td>\n",
       "      <td>2.976699</td>\n",
       "      <td>3.426356</td>\n",
       "      <td>3.944844</td>\n",
       "      <td>4.232551</td>\n",
       "      <td>2.173351</td>\n",
       "      <td>2.273015</td>\n",
       "      <td>6.026444</td>\n",
       "      <td>6.010146</td>\n",
       "      <td>MCAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.331988</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>3.125354</td>\n",
       "      <td>3.570151</td>\n",
       "      <td>3.630813</td>\n",
       "      <td>2.891829</td>\n",
       "      <td>2.891829</td>\n",
       "      <td>4.273808</td>\n",
       "      <td>5.297177</td>\n",
       "      <td>7.510740</td>\n",
       "      <td>...</td>\n",
       "      <td>2.346861</td>\n",
       "      <td>3.570151</td>\n",
       "      <td>2.414528</td>\n",
       "      <td>3.368204</td>\n",
       "      <td>4.119319</td>\n",
       "      <td>2.729975</td>\n",
       "      <td>2.684824</td>\n",
       "      <td>5.862211</td>\n",
       "      <td>5.935485</td>\n",
       "      <td>MCAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.619051</td>\n",
       "      <td>1.974893</td>\n",
       "      <td>2.605541</td>\n",
       "      <td>3.519751</td>\n",
       "      <td>2.948207</td>\n",
       "      <td>2.404832</td>\n",
       "      <td>3.137391</td>\n",
       "      <td>4.295079</td>\n",
       "      <td>4.585000</td>\n",
       "      <td>7.673688</td>\n",
       "      <td>...</td>\n",
       "      <td>2.544092</td>\n",
       "      <td>2.905994</td>\n",
       "      <td>2.544092</td>\n",
       "      <td>3.662709</td>\n",
       "      <td>4.478651</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>2.477620</td>\n",
       "      <td>6.219767</td>\n",
       "      <td>5.997715</td>\n",
       "      <td>MCAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.021363</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>2.913924</td>\n",
       "      <td>3.443582</td>\n",
       "      <td>3.627241</td>\n",
       "      <td>2.838415</td>\n",
       "      <td>2.937903</td>\n",
       "      <td>4.301555</td>\n",
       "      <td>4.861119</td>\n",
       "      <td>7.184987</td>\n",
       "      <td>...</td>\n",
       "      <td>2.152548</td>\n",
       "      <td>3.050253</td>\n",
       "      <td>2.454656</td>\n",
       "      <td>3.666083</td>\n",
       "      <td>3.930574</td>\n",
       "      <td>2.567736</td>\n",
       "      <td>2.214481</td>\n",
       "      <td>5.709837</td>\n",
       "      <td>5.492568</td>\n",
       "      <td>MCAV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3485 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A0A011QK89  A0A023I7E1  A0A067XMP1  A0A067YMX8  A0A075HNX4  A0A0A0RM07  \\\n",
       "0    3.907570    1.620841    3.004398    2.703474    2.986870    2.241169   \n",
       "1    5.441870    1.620841    2.535626    3.657173    3.478619    2.503367   \n",
       "2    5.331988    1.620841    3.125354    3.570151    3.630813    2.891829   \n",
       "3    5.619051    1.974893    2.605541    3.519751    2.948207    2.404832   \n",
       "4    5.021363    1.620841    2.913924    3.443582    3.627241    2.838415   \n",
       "\n",
       "   A0A0B4KGY6  A0A0B6VQ48  A0A0B7P9G0  A0A0G2JDV3  ...    S8GJB7    V6CLA2  \\\n",
       "0    2.521235    3.692186    3.004398    6.353335  ...  1.620841  1.856850   \n",
       "1    3.106804    4.619353    4.672777    7.503357  ...  1.869137  2.976699   \n",
       "2    2.891829    4.273808    5.297177    7.510740  ...  2.346861  3.570151   \n",
       "3    3.137391    4.295079    4.585000    7.673688  ...  2.544092  2.905994   \n",
       "4    2.937903    4.301555    4.861119    7.184987  ...  2.152548  3.050253   \n",
       "\n",
       "     W0LYS5    W0TIW1    W7JLR6    W7JX98    W7K9M0    W7NDQ0    X1WER2  Host  \n",
       "0  3.104000  3.119761  3.371791  1.856850  2.359892  4.727864  4.686284  MCAV  \n",
       "1  3.426356  3.944844  4.232551  2.173351  2.273015  6.026444  6.010146  MCAV  \n",
       "2  2.414528  3.368204  4.119319  2.729975  2.684824  5.862211  5.935485  MCAV  \n",
       "3  2.544092  3.662709  4.478651  1.620841  2.477620  6.219767  5.997715  MCAV  \n",
       "4  2.454656  3.666083  3.930574  2.567736  2.214481  5.709837  5.492568  MCAV  \n",
       "\n",
       "[5 rows x 3485 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the column that are not taken into consideration.\n",
    "data = data.drop(['Sample_ID','Clade', 'Dominant' ],axis = 1)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A0A011QK89</th>\n",
       "      <th>A0A023I7E1</th>\n",
       "      <th>A0A067XMP1</th>\n",
       "      <th>A0A067YMX8</th>\n",
       "      <th>A0A075HNX4</th>\n",
       "      <th>A0A0A0RM07</th>\n",
       "      <th>A0A0B4KGY6</th>\n",
       "      <th>A0A0B6VQ48</th>\n",
       "      <th>A0A0B7P9G0</th>\n",
       "      <th>A0A0G2JDV3</th>\n",
       "      <th>...</th>\n",
       "      <th>S8GJB7</th>\n",
       "      <th>V6CLA2</th>\n",
       "      <th>W0LYS5</th>\n",
       "      <th>W0TIW1</th>\n",
       "      <th>W7JLR6</th>\n",
       "      <th>W7JX98</th>\n",
       "      <th>W7K9M0</th>\n",
       "      <th>W7NDQ0</th>\n",
       "      <th>X1WER2</th>\n",
       "      <th>Host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.907570</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>3.004398</td>\n",
       "      <td>2.703474</td>\n",
       "      <td>2.986870</td>\n",
       "      <td>2.241169</td>\n",
       "      <td>2.521235</td>\n",
       "      <td>3.692186</td>\n",
       "      <td>3.004398</td>\n",
       "      <td>6.353335</td>\n",
       "      <td>...</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>1.856850</td>\n",
       "      <td>3.104000</td>\n",
       "      <td>3.119761</td>\n",
       "      <td>3.371791</td>\n",
       "      <td>1.856850</td>\n",
       "      <td>2.359892</td>\n",
       "      <td>4.727864</td>\n",
       "      <td>4.686284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.441870</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>2.535626</td>\n",
       "      <td>3.657173</td>\n",
       "      <td>3.478619</td>\n",
       "      <td>2.503367</td>\n",
       "      <td>3.106804</td>\n",
       "      <td>4.619353</td>\n",
       "      <td>4.672777</td>\n",
       "      <td>7.503357</td>\n",
       "      <td>...</td>\n",
       "      <td>1.869137</td>\n",
       "      <td>2.976699</td>\n",
       "      <td>3.426356</td>\n",
       "      <td>3.944844</td>\n",
       "      <td>4.232551</td>\n",
       "      <td>2.173351</td>\n",
       "      <td>2.273015</td>\n",
       "      <td>6.026444</td>\n",
       "      <td>6.010146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.331988</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>3.125354</td>\n",
       "      <td>3.570151</td>\n",
       "      <td>3.630813</td>\n",
       "      <td>2.891829</td>\n",
       "      <td>2.891829</td>\n",
       "      <td>4.273808</td>\n",
       "      <td>5.297177</td>\n",
       "      <td>7.510740</td>\n",
       "      <td>...</td>\n",
       "      <td>2.346861</td>\n",
       "      <td>3.570151</td>\n",
       "      <td>2.414528</td>\n",
       "      <td>3.368204</td>\n",
       "      <td>4.119319</td>\n",
       "      <td>2.729975</td>\n",
       "      <td>2.684824</td>\n",
       "      <td>5.862211</td>\n",
       "      <td>5.935485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.619051</td>\n",
       "      <td>1.974893</td>\n",
       "      <td>2.605541</td>\n",
       "      <td>3.519751</td>\n",
       "      <td>2.948207</td>\n",
       "      <td>2.404832</td>\n",
       "      <td>3.137391</td>\n",
       "      <td>4.295079</td>\n",
       "      <td>4.585000</td>\n",
       "      <td>7.673688</td>\n",
       "      <td>...</td>\n",
       "      <td>2.544092</td>\n",
       "      <td>2.905994</td>\n",
       "      <td>2.544092</td>\n",
       "      <td>3.662709</td>\n",
       "      <td>4.478651</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>2.477620</td>\n",
       "      <td>6.219767</td>\n",
       "      <td>5.997715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.021363</td>\n",
       "      <td>1.620841</td>\n",
       "      <td>2.913924</td>\n",
       "      <td>3.443582</td>\n",
       "      <td>3.627241</td>\n",
       "      <td>2.838415</td>\n",
       "      <td>2.937903</td>\n",
       "      <td>4.301555</td>\n",
       "      <td>4.861119</td>\n",
       "      <td>7.184987</td>\n",
       "      <td>...</td>\n",
       "      <td>2.152548</td>\n",
       "      <td>3.050253</td>\n",
       "      <td>2.454656</td>\n",
       "      <td>3.666083</td>\n",
       "      <td>3.930574</td>\n",
       "      <td>2.567736</td>\n",
       "      <td>2.214481</td>\n",
       "      <td>5.709837</td>\n",
       "      <td>5.492568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3485 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A0A011QK89  A0A023I7E1  A0A067XMP1  A0A067YMX8  A0A075HNX4  A0A0A0RM07  \\\n",
       "0    3.907570    1.620841    3.004398    2.703474    2.986870    2.241169   \n",
       "1    5.441870    1.620841    2.535626    3.657173    3.478619    2.503367   \n",
       "2    5.331988    1.620841    3.125354    3.570151    3.630813    2.891829   \n",
       "3    5.619051    1.974893    2.605541    3.519751    2.948207    2.404832   \n",
       "4    5.021363    1.620841    2.913924    3.443582    3.627241    2.838415   \n",
       "\n",
       "   A0A0B4KGY6  A0A0B6VQ48  A0A0B7P9G0  A0A0G2JDV3  ...    S8GJB7    V6CLA2  \\\n",
       "0    2.521235    3.692186    3.004398    6.353335  ...  1.620841  1.856850   \n",
       "1    3.106804    4.619353    4.672777    7.503357  ...  1.869137  2.976699   \n",
       "2    2.891829    4.273808    5.297177    7.510740  ...  2.346861  3.570151   \n",
       "3    3.137391    4.295079    4.585000    7.673688  ...  2.544092  2.905994   \n",
       "4    2.937903    4.301555    4.861119    7.184987  ...  2.152548  3.050253   \n",
       "\n",
       "     W0LYS5    W0TIW1    W7JLR6    W7JX98    W7K9M0    W7NDQ0    X1WER2  Host  \n",
       "0  3.104000  3.119761  3.371791  1.856850  2.359892  4.727864  4.686284     0  \n",
       "1  3.426356  3.944844  4.232551  2.173351  2.273015  6.026444  6.010146     0  \n",
       "2  2.414528  3.368204  4.119319  2.729975  2.684824  5.862211  5.935485     0  \n",
       "3  2.544092  3.662709  4.478651  1.620841  2.477620  6.219767  5.997715     0  \n",
       "4  2.454656  3.666083  3.930574  2.567736  2.214481  5.709837  5.492568     0  \n",
       "\n",
       "[5 rows x 3485 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Coral HOST into numericals by making HOST == OANN as 1 and HOST != OANN as 0.\n",
    "data['Host'] = (data['Host'] == 'OANN').astype(int)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HOST is our Target and the rest of the data is the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target column\n",
    "y = data['Host']\n",
    "# Inputs of the target column\n",
    "X = data.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV Accuracy: 0.9714285714285715\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation \n",
    "# Defining the cross validation accuracy.\n",
    "lr = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "# Cross Validation Accuracy with a fold of 5.\n",
    "cv_score = cross_val_score(lr, X_train, y_train, cv = 5, scoring = 'accuracy')\n",
    "print(\"Logistic Regression CV Accuracy:\", cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model with all parameters and testing the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Testing Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# FItting the model.\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the results on the testing set.4\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# FInding the Accurayc of the logistic Reqgression Model.\n",
    "Accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Logistic Regression Testing Accuracy:\", Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the confusion Matrix of the predictions and finding the Error rate fo the Predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------------------+----------------------+\n",
      "| Confusion Matrix:   |   Predicted Positive |   Predicted Negative |\n",
      "+=====================+======================+======================+\n",
      "| Actual Positive     |                    7 |                    0 |\n",
      "+---------------------+----------------------+----------------------+\n",
      "| Actual Negative     |                    1 |                    1 |\n",
      "+---------------------+----------------------+----------------------+\n",
      "Error Rate: 0.1111\n"
     ]
    }
   ],
   "source": [
    "# Assuming y_test and y_pred are already defined\n",
    "cons_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate the error rate\n",
    "Error_rate = (cons_matrix[0, 1] + cons_matrix[1, 0]) / cons_matrix.sum()\n",
    "\n",
    "# Prepare table data\n",
    "table_data = [\n",
    "    [\"Actual Positive\", cons_matrix[0, 0], cons_matrix[0, 1]],\n",
    "    [\"Actual Negative\", cons_matrix[1, 0], cons_matrix[1, 1]]\n",
    "]\n",
    "\n",
    "# Defining the headers\n",
    "headers = [\"Confusion Matrix:\", \"Predicted Positive\", \"Predicted Negative\"]\n",
    "\n",
    "print(tabulate(table_data, headers, tablefmt = \"grid\"))\n",
    "print(f\"Error Rate: {Error_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the feature importance for the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of significant features required for the resutls within in top 32% important features : 458\n",
      "The number of significant features required for the resutls within in top 5% important features : 179\n",
      "Top 10 features contributing to the results:-\n",
      "['Q8ZRS8', 'P46285', 'Q43011', 'Q9SF16', 'Q0V6P9', 'Q53RK8', 'Q94B38', 'Q0WKV3', 'Q28057', 'Q3ZBH0']\n"
     ]
    }
   ],
   "source": [
    "# Get the coefficients and corresponding feature names\n",
    "coefficients = lr.coef_[0]\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame to display coefficients and feature names\n",
    "coefficients_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "\n",
    "# Display the DataFrame sorted by absolute coefficient values\n",
    "coefficients_df['Absolute Coefficient'] = coefficients_df['Coefficient'].abs()\n",
    "sorted_coefficients = coefficients_df.sort_values(by='Absolute Coefficient', ascending = False)\n",
    "\n",
    "# Calculate the mean and standard deviation of the absolute coefficients\n",
    "mean_coeff = np.mean(sorted_coefficients['Absolute Coefficient'].abs())\n",
    "std_coeff = np.std(sorted_coefficients['Absolute Coefficient'].abs())\n",
    "\n",
    "# Setting the threshold\n",
    "threshold = mean_coeff + std_coeff\n",
    "\n",
    "# Select features with absolute coefficients greater than the threshold\n",
    "significant_features = sorted_coefficients[sorted_coefficients['Absolute Coefficient'].abs() > threshold]\n",
    "print(f\"The number of significant features required for the resutls within in top 32% important features : {len(significant_features)}\")\n",
    "\n",
    "# Setting the threshold\n",
    "threshold = mean_coeff + std_coeff*2\n",
    "# Select features with absolute coefficients greater than the threshold\n",
    "significant_features = sorted_coefficients[sorted_coefficients['Absolute Coefficient'].abs() > threshold]\n",
    "print(f\"The number of significant features required for the resutls within in top 5% important features : {len(significant_features)}\")\n",
    "\n",
    "# Top 10 important features\n",
    "print(\"Top 10 features contributing to the results:-\")\n",
    "top_features = sorted_coefficients['Feature'].head(10)\n",
    "print(top_features.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tunning for Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FitFailedWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = [\n",
    "    {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga'], 'max_iter': [100, 200, 300]},\n",
    "    {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['elasticnet'], 'solver': ['saga'], 'max_iter': [100, 200, 300]}\n",
    "]\n",
    "\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters and the corresponding score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model with the best parameters and predicting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Testing Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# Creating the logistic regression object.\n",
    "lr = LogisticRegression(C= 0.01, max_iter= 1000, penalty= 'l2', solver= 'liblinear')\n",
    "\n",
    "# FItting the model.\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the results on the testing set.4\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# FInding the Accurayc of the logistic Reqgression Model.\n",
    "Accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Logistic Regression Testing Accuracy:\", Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Questions \n",
    "\n",
    "### 1) How Many Genes/Components Are Obtained/Required Significant Results? \n",
    "  In this question, based on your algorithm, are there a certain number of genes or components (depending on the algorithm) that can perform the classification of your problem? \n",
    "\n",
    "- The number of significant features required for the resutls within in top 32% important features : 458\n",
    "- The number of significant features required for the resutls within in top 5% important features : 179\n",
    "- Top 10 features contributing to the results can do the classification:-\n",
    "- ['Q8ZRS8', 'P46285', 'Q43011', 'Q9SF16', 'Q0V6P9', 'Q53RK8', 'Q94B38', 'Q0WKV3', 'Q28057', 'Q3ZBH0']\n",
    "\n",
    "### 2) What is the Error Rate of These Algorithms? \n",
    "  In this question, based on your algorithms, how much of the test dataset is misclassified?\n",
    "\n",
    "- Error Rate is 0.111 for the test dataset. Only 1 is misclassified.\n",
    "  \n",
    "### 3) What are two genes that were signficiantly correlated to your problem? \n",
    "  In this question, based on your algorithm, identify and annotate 2 genes using [uniprot](uniprot.org). Do you think they are biologically relevant? \n",
    "\n",
    "- Aconitate Hydratase B (AcnB) from Salmonella typhimurium (Q8ZRS8 · ACNB_SALTY):\n",
    "\n",
    "Function: Involved in the catabolism of short-chain fatty acids via the tricarboxylic acid (TCA) cycle and the 2-methylcitrate cycle. It catalyzes the reversible isomerization of citrate to isocitrate and the hydration of 2-methyl-cis-aconitate.\n",
    "Biological Relevance: The TCA cycle is a key metabolic pathway that provides energy and precursors for biosynthesis. In the context of Cladacopium, this enzyme could be crucial for energy metabolism. The ability to process various carbon sources, including short-chain fatty acids, might be significant in the symbiotic relationship, possibly affecting the nutrient exchange dynamics.\n",
    "\n",
    "- Sedoheptulose-1,7-bisphosphatase, Chloroplastic from Triticum aestivum (Wheat) (P46285 · S17P_WHEAT):\n",
    "\n",
    "Function: This enzyme plays a role in the Calvin cycle, which is involved in photosynthesis.\n",
    "Biological Relevance: In relation to Cladacopium, which are photosynthetic algae living in coral tissues, this enzyme could be significant for photosynthesis and carbon fixation. Its role in the Calvin cycle implies its importance in converting carbon dioxide into organic compounds, which is vital for the symbiotic relationship in providing nutrients to the coral host.\n",
    "\n",
    "- Given their functions in crucial metabolic pathways, both enzymes are likely to be biologically relevant in the context of Cladacopium, especially considering the metabolic and photosynthetic processes essential for the symbiosis with coral hosts. \n",
    "\n",
    "### 4) What can we infer about this dataset based on these results? \n",
    "  In this question, you should think about the overall classification results of this algorithm. Does the type of algorithm used here tell you anything about the data in this study? What is biologically meaningful about this? \n",
    "\n",
    "- From the results 88% of accuracy on test data, 97.14% Cross validation accuracy and the predictions of Logistic Regression algorithm used can provide insights into whether the focus is on expression patterns, functional annotations, or evolutionary relationships, each offering different perspectives on the biological significance of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing cross validation on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant Analysis Cross-validated Accuracy: 0.9428571428571428\n"
     ]
    }
   ],
   "source": [
    "# Initializing the LDA model\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Performing a  5-fold cross-validation on the training data to evaluate the model's performance\n",
    "cv_score = cross_val_score(lda, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the mean cross-validated accuracy score\n",
    "print(\"Linear Discriminant Analysis Cross-validated Accuracy:\", cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model and predicting the results on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant Analysis Test data Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# Fitting the LDA model to the training data\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = lda.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy score on the test set\n",
    "# 'y_test' are the true labels for the test data\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Linear Discriminant Analysis Test data Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding different matrices of evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Values:\n",
      " [-22.51474059 -21.3001699   -5.5964112  -24.98414154 -33.95100689\n",
      " -24.87532512  21.31513501 -16.56494812 -23.70147123]\n",
      "\n",
      "Predicted Probabilities:\n",
      " [[1.00000000e+00 1.66714126e-10]\n",
      " [9.99999999e-01 5.61634463e-10]\n",
      " [9.96302563e-01 3.69743668e-03]\n",
      " [1.00000000e+00 1.41099409e-11]\n",
      " [1.00000000e+00 1.79996912e-15]\n",
      " [1.00000000e+00 1.57319865e-11]\n",
      " [5.53292079e-10 9.99999999e-01]\n",
      " [9.99999936e-01 6.39638226e-08]\n",
      " [1.00000000e+00 5.08840687e-11]]\n",
      "\n",
      "Predicted Classes:\n",
      " [0 0 0 0 0 0 1 0 0]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.94      0.75      0.80         9\n",
      "weighted avg       0.90      0.89      0.87         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating the decision function value for each sample in the test set.\n",
    "# This value indicates the distance of each sample from the decision boundary.\n",
    "lda_DV = lda.decision_function(X_test)\n",
    "print(\"\\nDecision Values:\\n\", lda_DV)\n",
    "\n",
    "# Calculating the probability of each class for each sample in the test set.\n",
    "# These probabilities show the model's confidence in assigning each class to each sample.\n",
    "lda_PP = lda.predict_proba(X_test)\n",
    "print(\"\\nPredicted Probabilities:\\n\", lda_PP)\n",
    "\n",
    "# Predicting the class labels for the test set.\n",
    "# These are the final classifications made by the model for each sample.\n",
    "lda_PC = lda.predict(X_test)\n",
    "print(\"\\nPredicted Classes:\\n\", lda_PC)\n",
    "\n",
    "# Generating a classification report that includes key metrics like precision, recall, and F1-score.\n",
    "# This report provides a detailed analysis of the model's performance for each class.\n",
    "lda_CR = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\\n\", lda_CR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confustion Matrix of the LDA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------------------+----------------------+\n",
      "| Confusion Matrix:   |   Predicted Positive |   Predicted Negative |\n",
      "+=====================+======================+======================+\n",
      "| Actual Positive     |                    7 |                    0 |\n",
      "+---------------------+----------------------+----------------------+\n",
      "| Actual Negative     |                    1 |                    1 |\n",
      "+---------------------+----------------------+----------------------+\n",
      "Error Rate: 0.1111\n"
     ]
    }
   ],
   "source": [
    "# Assuming y_test and y_pred are already defined\n",
    "cons_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate the error rate\n",
    "Error_rate = (cons_matrix[0, 1] + cons_matrix[1, 0]) / cons_matrix.sum()\n",
    "\n",
    "# Prepare table data\n",
    "table_data = [\n",
    "    [\"Actual Positive\", cons_matrix[0, 0], cons_matrix[0, 1]],\n",
    "    [\"Actual Negative\", cons_matrix[1, 0], cons_matrix[1, 1]]\n",
    "]\n",
    "\n",
    "# Defining the headers\n",
    "headers = [\"Confusion Matrix:\", \"Predicted Positive\", \"Predicted Negative\"]\n",
    "\n",
    "print(tabulate(table_data, headers, tablefmt = \"grid\"))\n",
    "print(f\"Error Rate: {Error_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination (RFE)\n",
    "- RFE is a technique for selecting features by recursively considering smaller and smaller sets of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A0A075HNX4', 'A5FKJ2', 'B4GUZ2', 'B7GJ95', 'O30124', 'P07335', 'P22694', 'P32019', 'P32811', 'P51574', 'P9WKM1', 'Q0J9V3', 'Q23551', 'Q54FZ8', 'Q54GE3', 'Q54HL8', 'Q5M9G6', 'Q5RCS8', 'Q5UPD4', 'Q5YLM1', 'Q5ZKR7', 'Q68FR8', 'Q6GNI4', 'Q6ICB0', 'Q6P9J9', 'Q6S5H5', 'Q7RJG2', 'Q80ZA4', 'Q86WI1', 'Q86XH1', 'Q8GYH8', 'Q8L611', 'Q8L716', 'Q949Y0', 'Q9BSJ2', 'Q9BXP8', 'Q9EPK2', 'Q9HDZ5', 'Q9M271', 'Q9UJZ1']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Initialize LDA model\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Creating a list of the features using the columns of X\n",
    "features = X.columns.tolist()\n",
    "\n",
    "# Initialize RFE with the LDA model and the desired number of features\n",
    "rfe = RFE(lda, n_features_to_select = 40)\n",
    "\n",
    "# Fit RFE\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# Get the ranking of the features\n",
    "feature_ranking = rfe.ranking_\n",
    "\n",
    "# Select the top features based on ranking\n",
    "top_features = [features[i] for i in range(len(features)) if feature_ranking[i] == 1]\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the most influential features using the coefficient method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most influential genes: [('Q54GE3', 0.32893503837190824), ('B9F676', 0.3269164164157803), ('P54399', 0.30848877233608185), ('Q0VCN3', 0.2829772938120041), ('Q9HDZ5', 0.22735039343467034), ('Q96S16', 0.21421552854237969), ('A3LNF8', 0.20495138631202564), ('A1CUK5', 0.20481453412744383), ('O94264', 0.20306847313909698), ('Q55G18', 0.19048664760273734)]\n"
     ]
    }
   ],
   "source": [
    "# Creating the LDA object and fitting the model.\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Get the absolute coefficients for each gene\n",
    "coefficients = abs(lda.coef_[0])  # Assuming binary classification for simplicity\n",
    "\n",
    "# Combine gene names with their coefficients\n",
    "gene_importance = list(zip(features, coefficients))\n",
    "\n",
    "# Sorting the genes by their importance\n",
    "sorted_genes = sorted(gene_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the most influential genes\n",
    "print(\"Most influential genes:\", sorted_genes[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the number of genes that are significant to the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of significant genes present for the resutls within in top 32% important features : 310\n",
      "The number of significant genes present for the resutls within in top 5% important features : 105\n",
      "Top 10 features : ['Q54GE3', 'B9F676', 'P54399', 'Q0VCN3', 'Q9HDZ5', 'Q96S16', 'A3LNF8', 'A1CUK5', 'O94264', 'Q55G18']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean and standard deviation of the absolute coefficients\n",
    "mean_coeff = np.mean(coefficients)\n",
    "std_coeff = np.std(coefficients)\n",
    "\n",
    "# Setting the threshold\n",
    "threshold = mean_coeff + std_coeff\n",
    "\n",
    "# Extract genes with importance score above the threshold\n",
    "genes_above_threshold = [gene[0] for gene in sorted_genes if gene[1] > threshold]\n",
    "\n",
    "# Selecting features with absolute coefficients greater than the threshold\n",
    "print(f\"The number of significant genes present for the resutls within in top 32% important features : {len(genes_above_threshold)}\")\n",
    "\n",
    "# Setting the threshold\n",
    "threshold = mean_coeff + std_coeff*2\n",
    "# Selecting features with absolute coefficients greater than the threshold\n",
    "genes_above_threshold = [gene[0] for gene in sorted_genes if gene[1] > threshold]\n",
    "print(f\"The number of significant genes present for the resutls within in top 5% important features : {len(genes_above_threshold)}\")\n",
    "print(\"Top 10 features :\", genes_above_threshold[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q54GE3 and Q9HDZ5 are the two genes that are common in the most influential features and the features that are found by Recursive Feature Elimination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "\n",
    "### How Many Genes/Components Are Obtained/Required Significant Results? \n",
    "  In this question, based on your algorithm, are there a certain number of genes or components (depending on the algorithm) that can perform the classification of your problem? \n",
    "\n",
    "- The number of significant genes present for the resutls within in top 32% important features : 310\n",
    "- The number of significant genes present for the resutls within in top 5% important features : 105\n",
    "- Top 10 features that contribute to the classification are:- \n",
    "- ['Q54GE3', 'B9F676', 'P54399', 'Q0VCN3', 'Q9HDZ5', 'Q96S16', 'A3LNF8', 'A1CUK5', 'O94264', 'Q55G18']\n",
    "\n",
    "### What is the Error Rate of These Algorithms? \n",
    "  In this question, based on your algorithms, how much of the test dataset is misclassified?  \n",
    "- The Error Rate is similar to the results of the Logistic Regression. Only 1 is misclassified.\n",
    "  \n",
    "### What are two genes that were signficiantly correlated to your problem? \n",
    "  In this question, based on your algorithm, identify and annotate 2 genes using [uniprot](uniprot.org). Do you think they are biologically relevant? \n",
    "\n",
    "- Q54GE3 · VPS45_DICDI: \n",
    "- Involved in vesicle-mediated protein trafficking, particularly in the Golgi stack and trans-Golgi network. This process is crucial for cellular functioning, as it is involved in sorting and transporting proteins to their destination.\n",
    "\n",
    "- Q9HDZ5 · YKP9_SCHPO:\n",
    "- CRAL-TRIO domain-containing protein C589.09: Predicted to be mitochondrial, indicating a role in cellular energy metabolism or other mitochondrial functions. - - The CRAL-TRIO domain is often involved in binding small lipophilic molecules, suggesting a potential role in lipid metabolism or signaling.\n",
    "\n",
    "- While the direct relevance of these specific proteins to Cladacopium and its coral host might not be immediately clear, the functional roles they play in fundamental cellular processes could offer indirect insights into the biological mechanisms underlying symbiosis. We are unclear about the biologically direct relationship.\n",
    "\n",
    "### What can we infer about this dataset based on these results? \n",
    "  In this question, you should think about the overall classification results of this algorithm. Does the type of algorithm used here tell you anything about the data in this study? What is biologically meaningful about this?\n",
    "\n",
    "- The overall classification was similar to the results of the Logistic Regression with an Accuracy of 88% but the Cross validation accuracy of 94.28% is less than Logistic Regression. The identification of VPS45 and CRAL-TRIO domain-containing protein C589.09, and the use of LDA, suggest a focus on distinguishing cellular states or types based on fundamental biological processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation score with SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Cross-validated Accuracy: 0.9714285714285715\n"
     ]
    }
   ],
   "source": [
    "# Initializing the Support Vector Machine classifier with linear kernel and degree 5\n",
    "svm = SVC(kernel='linear', degree=5)\n",
    "\n",
    "# Performing 5-fold cross-validation to estimate the accuracy of the SVM\n",
    "cv_scores = cross_val_score(svm, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Support Vector Machine Cross-validated Accuracy:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Model using SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genes Used for Prediction:\n",
      " ['A0A023I7E1', 'A0A067XMP1', 'A0A0A0RM07', 'A0A0G2JDV3', 'A0A0G2JEB6', 'A0A0H2VDN9', 'A0A0I9QGZ2', 'A0A0K9RDW0', 'A0A0R4IBK5', 'A0A125YZN2', 'A0A1B4XBG9', 'A0A1D8PDZ1', 'A0A4V8H042', 'A0A075HNX4', 'A0A0B4KGY6', 'A0A0B6VQ48']\n"
     ]
    }
   ],
   "source": [
    "# Fitting the SVM model to the training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Retrieving the indices of the support vectors\n",
    "support_vector_indices = svm.support_\n",
    "\n",
    "# Extracting the gene names corresponding to the support vector indices\n",
    "selected_genes = X_train.columns[support_vector_indices]\n",
    "print(\"Genes Used for Prediction:\\n\", selected_genes.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation using the Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Test Set Accuracy: 0.8888888888888888\n",
      "Number of Components (Support Vectors): 16\n"
     ]
    }
   ],
   "source": [
    "# Predicting the labels for the test set\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Calculating the accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Support Vector Machine Test Set Accuracy:\", test_accuracy)\n",
    "\n",
    "# Displaying the number of support vectors used in the model\n",
    "print(\"Number of Components (Support Vectors):\", svm.support_vectors_.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning of SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .......C=0.1, gamma=1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .......C=0.1, gamma=1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .......C=0.1, gamma=1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .......C=0.1, gamma=1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .C=0.1, gamma=0.001, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .C=0.1, gamma=0.001, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .C=0.1, gamma=0.001, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .C=0.1, gamma=0.001, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END .........C=1, gamma=1, kernel=poly;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .........C=1, gamma=1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .........C=1, gamma=1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .........C=1, gamma=1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .........C=1, gamma=1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, gamma=0.01, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, gamma=0.01, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, gamma=0.01, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, gamma=0.01, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.01, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.01, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.01, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.01, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ...C=1, gamma=0.001, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...C=1, gamma=0.001, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, gamma=0.001, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=1, gamma=0.001, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.001, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.001, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.001, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.001, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END ........C=10, gamma=1, kernel=poly;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ........C=10, gamma=1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ........C=10, gamma=1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ........C=10, gamma=1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ........C=10, gamma=1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ...C=10, gamma=0.01, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...C=10, gamma=0.01, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ...C=10, gamma=0.01, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=10, gamma=0.01, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.01, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.01, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.01, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.01, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, gamma=0.001, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, gamma=0.001, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, gamma=0.001, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..C=10, gamma=0.001, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.001, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.001, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.001, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.001, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END .......C=100, gamma=1, kernel=poly;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .......C=100, gamma=1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .......C=100, gamma=1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .......C=100, gamma=1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .......C=100, gamma=1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.1, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ..C=100, gamma=0.01, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ..C=100, gamma=0.01, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ..C=100, gamma=0.01, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..C=100, gamma=0.01, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.01, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.01, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.01, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.01, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .C=100, gamma=0.001, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .C=100, gamma=0.001, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .C=100, gamma=0.001, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .C=100, gamma=0.001, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .C=100, gamma=0.001, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.001, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.001, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.001, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.001, kernel=poly;, score=1.000 total time=   0.0s\n",
      "Best Parameters: {'C': 0.1, 'gamma': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for SVM\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "# Creating a GridSearchCV object to find the best parameters\n",
    "grid_search = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, cv = 5)\n",
    "\n",
    "# Fitting the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Printing the best parameters found by GridSearchCV\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction using the best Parameters from teh Hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned SVM Test Set Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# Predicting with the best estimator\n",
    "y_pred_tuned = grid_search.predict(X_test)\n",
    "\n",
    "# Calculating the accuracy on the test set with the tuned parameters\n",
    "tuned_accuracy = accuracy_score(y_test, y_pred_tuned)\n",
    "print(\"Tuned SVM Test Set Accuracy:\", tuned_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix for SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------------------+----------------------+\n",
      "| Confusion Matrix:   |   Predicted Positive |   Predicted Negative |\n",
      "+=====================+======================+======================+\n",
      "| Actual Positive     |                    7 |                    0 |\n",
      "+---------------------+----------------------+----------------------+\n",
      "| Actual Negative     |                    1 |                    1 |\n",
      "+---------------------+----------------------+----------------------+\n",
      "Error Rate: 0.1111\n"
     ]
    }
   ],
   "source": [
    "# Assuming y_test and y_pred are already defined\n",
    "cons_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate the error rate\n",
    "Error_rate = (cons_matrix[0, 1] + cons_matrix[1, 0]) / cons_matrix.sum()\n",
    "\n",
    "# Prepare table data\n",
    "table_data = [\n",
    "    [\"Actual Positive\", cons_matrix[0, 0], cons_matrix[0, 1]],\n",
    "    [\"Actual Negative\", cons_matrix[1, 0], cons_matrix[1, 1]]\n",
    "]\n",
    "\n",
    "# Defining the headers\n",
    "headers = [\"Confusion Matrix:\", \"Predicted Positive\", \"Predicted Negative\"]\n",
    "\n",
    "print(tabulate(table_data, headers, tablefmt = \"grid\"))\n",
    "print(f\"Error Rate: {Error_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the most significant genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 Significant Genes:\n",
      " [('Q8ZRS8', 0.003722035964487068), ('Q9SF16', 0.0036126978014409186)]\n",
      "Gene: Q8ZRS8, Weight: 0.003722035964487068\n",
      "Gene: Q9SF16, Weight: 0.0036126978014409186\n"
     ]
    }
   ],
   "source": [
    "# Finding the coefficients of SVM.\n",
    "coefficients = svm.coef_[0]\n",
    "\n",
    "# Ranking the genes by the absolute values of the coefficients\n",
    "gene_importance = sorted(zip(X_train.columns, coefficients), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Selecting the top 2 significant genes\n",
    "top_genes = gene_importance[:2]\n",
    "print(\"Top 2 Significant Genes:\\n\", top_genes)\n",
    "\n",
    "# Annotate these genes\n",
    "for gene, weight in top_genes:\n",
    "    # Perform a literature search or database query for each gene\n",
    "    # Annotate the biological relevance based on your findings\n",
    "    print(f\"Gene: {gene}, Weight: {weight}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "\n",
    "### How Many Genes/Components Are Obtained/Required Significant Results? \n",
    "  In this question, based on your algorithm, are there a certain number of genes or components (depending on the algorithm) that can perform the classification of your problem? \n",
    "\n",
    "- For the Support Vector machines 16 components can perform the classification of your problem.\n",
    "- The genes used for Prediction are 'A0A023I7E1', 'A0A067XMP1', 'A0A0A0RM07', 'A0A0G2JDV3', 'A0A0G2JEB6', 'A0A0H2VDN9', 'A0A0I9QGZ2', 'A0A0K9RDW0', 'A0A0R4IBK5', 'A0A125YZN2', 'A0A1B4XBG9', 'A0A1D8PDZ1', 'A0A4V8H042', 'A0A075HNX4', 'A0A0B4KGY6', 'A0A0B6VQ48'\n",
    "\n",
    "### What is the Error Rate of These Algorithms? \n",
    "  In this question, based on your algorithms, how much of the test dataset is misclassified? \n",
    "\n",
    "- The Error Rate of the SVM is 0.1111 and only 1 value is misclassified.\n",
    "\n",
    "### What are two genes that were signficiantly correlated to your problem? \n",
    "  In this question, based on your algorithm, identify and annotate 2 genes using [uniprot](uniprot.org). Do you think they are biologically relevant? \n",
    "\n",
    "T-complex Protein 1 Subunit Eta (CCT7) - Arabidopsis thaliana ( Q9SF16 · TCPH_ARATH ):\n",
    "\n",
    "- Function: Acts as a molecular chaperone, assisting in the folding of proteins upon ATP hydrolysis. It plays a role in the folding of actin and tubulin, which are crucial for cellular structure and dynamics.\n",
    "- Relevance to Cladacopium: In the context of Cladacopium, protein folding and structural integrity are essential for maintaining cellular function, especially under stress conditions prevalent in symbiotic environments. Molecular chaperones like CCT7 might be crucial in ensuring the proper functioning of proteins that sustain the photosynthetic and metabolic activities of the algae.\n",
    "\n",
    "Aconitate Hydratase B (AcnB) - Salmonella typhimurium ( Q8ZRS8 · ACNB_SALTY ):\n",
    "\n",
    "- Function: Involved in the catabolism of short-chain fatty acids through the TCA cycle and the 2-methylcitrate cycle. It plays a role in isomerizing citrate to isocitrate and in the hydration of 2-methyl-cis-aconitate.\n",
    "- Relevance to Cladacopium: The TCA cycle is fundamental for energy metabolism. In Cladacopium, efficient energy metabolism is crucial for sustaining the symbiotic relationship with coral hosts. The ability to process various carbon sources might impact the nutrient exchange and energy dynamics within the symbiosis.\n",
    "\n",
    "### What can we infer about this dataset based on these results? \n",
    "  In this question, you should think about the overall classification results of this algorithm. Does the type of algorithm used here tell you anything about the data in this study? What is biologically meaningful about this? \n",
    "The Support vector machines are able to perform with an Cross validation accuracy of 97.14% which is good. The fact that these proteins Q8ZRS8 · ACNB_SALTY and Q9SF16 · TCPH_ARATH were highlighted as significant features in an SVM analysis suggests they might have distinctive roles or expressions in certain conditions or states.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls = PLSRegression(n_components=5) \n",
    "y_pred_cv = cross_val_predict(pls, X_train, y_train, cv=5)\n",
    "threshold = 0.5 \n",
    "y_pred_cv = (y_pred_cv > threshold).astype(int)\n",
    "cv_accuracy = accuracy_score(y_train, y_pred_cv)\n",
    "print(\"Partial Least Square Cross-validated Accuracy:\", cv_accuracy)\n",
    "pls.fit(X_train, y_train)\n",
    "y_pred = pls.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_pred_binary = (y_pred > threshold).astype(int)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Partial Least Square Test Set Accuracy:\", test_accuracy)\n",
    "error_rate = 1 - test_accuracy\n",
    "print(f\"Error Rate for Partial Least Square : {error_rate}\")\n",
    "loadings_component_1 = pls.x_weights_[:, 0]\n",
    "top_gene_indices = loadings_component_1.argsort()[-5:][::-1]\n",
    "top_genes = X_train.columns[top_gene_indices]\n",
    "print(\"Top Genes for PLS Method: \", top_genes)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_binary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
